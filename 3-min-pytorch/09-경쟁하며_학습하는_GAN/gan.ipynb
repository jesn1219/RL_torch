{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN으로 새로운 패션아이템 생성하기\n",
    "*GAN을 이용하여 새로운 패션 아이템을 만들어봅니다*\n",
    "\n",
    "이 프로젝트는 최윤제님의 파이토치 튜토리얼 사용 허락을 받아 참고했습니다.\n",
    "\n",
    "* [yunjey/pytorch-tutorial](https://github.com/yunjey/pytorch-tutorial) - MIT License"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EPOCHS 과 BATCH_SIZE 등 학습에 필요한 하이퍼 파라미터 들을 설정해 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터\n",
    "EPOCHS = 500\n",
    "BATCH_SIZE = 100\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "print(\"Using Device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습에 필요한 데이터셋을 로딩합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./.data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./.data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./.data/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./.data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "111.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./.data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./.data/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./.data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./.data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./.data/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./.data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "159.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./.data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./.data/FashionMNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Fashion MNIST 데이터셋\n",
    "trainset = datasets.FashionMNIST(\n",
    "    './.data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "       transforms.ToTensor(),\n",
    "       transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset     = trainset,\n",
    "    batch_size  = BATCH_SIZE,\n",
    "    shuffle     = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "생성자는 64차원의 랜덤한 텐서를 입력받아 이에 행렬곱(Linear)과 활성화 함수(ReLU, Tanh) 연산을 실행합니다. 생성자의 결과값은 784차원, 즉 Fashion MNIST 속의 이미지와 같은 차원의 텐서입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성자 (Generator)\n",
    "G = nn.Sequential(\n",
    "        nn.Linear(64, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, 784),\n",
    "        nn.Tanh())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "판별자는 784차원의 텐서를 입력받습니다. 판별자 역시 입력된 데이터에 행렬곱과 활성화 함수를 실행시키지만, 생성자와 달리 판별자의 결과값은 입력받은 텐서가 진짜인지 구분하는 예측값입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 판별자 (Discriminator)\n",
    "D = nn.Sequential(\n",
    "        nn.Linear(784, 256),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        nn.Linear(256, 256),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        nn.Linear(256, 1),\n",
    "        nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "생성자와 판별자 학습에 쓰일 오차 함수와 최적화 알고리즘도 정의해 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델의 가중치를 지정한 장치로 보내기\n",
    "D = D.to(DEVICE)\n",
    "G = G.to(DEVICE)\n",
    "\n",
    "# 이진 크로스 엔트로피 (Binary cross entropy) 오차 함수와\n",
    "# 생성자와 판별자를 최적화할 Adam 모듈\n",
    "criterion = nn.BCELoss()\n",
    "d_optimizer = optim.Adam(D.parameters(), lr=0.0002)\n",
    "g_optimizer = optim.Adam(G.parameters(), lr=0.0002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 학습에 필요한 준비는 끝났습니다. 그럼 본격적으로 GAN을 학습시키는 loop을 만들어 보겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/500], d_loss: 0.0437, g_loss: 4.2856, D(x): 0.99, D(G(z)): 0.03\n",
      "Epoch [1/500], d_loss: 0.0409, g_loss: 5.1594, D(x): 0.98, D(G(z)): 0.02\n",
      "Epoch [2/500], d_loss: 0.0798, g_loss: 7.4819, D(x): 0.98, D(G(z)): 0.02\n",
      "Epoch [3/500], d_loss: 0.0419, g_loss: 6.3221, D(x): 0.98, D(G(z)): 0.00\n",
      "Epoch [4/500], d_loss: 0.0509, g_loss: 5.7419, D(x): 0.99, D(G(z)): 0.03\n",
      "Epoch [5/500], d_loss: 0.0263, g_loss: 6.8491, D(x): 0.99, D(G(z)): 0.01\n",
      "Epoch [6/500], d_loss: 0.1469, g_loss: 5.1516, D(x): 0.96, D(G(z)): 0.04\n",
      "Epoch [7/500], d_loss: 0.1119, g_loss: 4.7306, D(x): 0.98, D(G(z)): 0.05\n",
      "Epoch [8/500], d_loss: 0.1418, g_loss: 7.2146, D(x): 0.94, D(G(z)): 0.01\n",
      "Epoch [9/500], d_loss: 0.4591, g_loss: 4.2048, D(x): 0.87, D(G(z)): 0.12\n",
      "Epoch [10/500], d_loss: 0.3810, g_loss: 4.0554, D(x): 0.87, D(G(z)): 0.02\n",
      "Epoch [11/500], d_loss: 0.2047, g_loss: 5.0401, D(x): 0.93, D(G(z)): 0.04\n",
      "Epoch [12/500], d_loss: 0.1160, g_loss: 4.5769, D(x): 0.95, D(G(z)): 0.04\n",
      "Epoch [13/500], d_loss: 0.2420, g_loss: 4.3442, D(x): 0.91, D(G(z)): 0.04\n",
      "Epoch [14/500], d_loss: 0.1978, g_loss: 3.8848, D(x): 0.92, D(G(z)): 0.05\n",
      "Epoch [15/500], d_loss: 0.3035, g_loss: 3.3212, D(x): 0.90, D(G(z)): 0.10\n",
      "Epoch [16/500], d_loss: 0.4565, g_loss: 3.3194, D(x): 0.85, D(G(z)): 0.08\n",
      "Epoch [17/500], d_loss: 0.2779, g_loss: 4.1496, D(x): 0.91, D(G(z)): 0.08\n",
      "Epoch [18/500], d_loss: 0.2313, g_loss: 3.5643, D(x): 0.93, D(G(z)): 0.09\n",
      "Epoch [19/500], d_loss: 0.3712, g_loss: 3.0717, D(x): 0.88, D(G(z)): 0.12\n",
      "Epoch [20/500], d_loss: 0.5173, g_loss: 2.8786, D(x): 0.83, D(G(z)): 0.13\n",
      "Epoch [21/500], d_loss: 0.2245, g_loss: 4.3734, D(x): 0.90, D(G(z)): 0.05\n",
      "Epoch [22/500], d_loss: 0.3483, g_loss: 3.9351, D(x): 0.89, D(G(z)): 0.07\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_loader)\n",
    "for epoch in range(EPOCHS):\n",
    "    for i, (images, _) in enumerate(train_loader):\n",
    "        images = images.reshape(BATCH_SIZE, -1).to(DEVICE)\n",
    "        \n",
    "        # '진짜'와 '가짜' 레이블 생성\n",
    "        real_labels = torch.ones(BATCH_SIZE, 1).to(DEVICE)\n",
    "        fake_labels = torch.zeros(BATCH_SIZE, 1).to(DEVICE)\n",
    "        \n",
    "        # 판별자가 진짜 이미지를 진짜로 인식하는 오차를 예산\n",
    "        outputs = D(images)\n",
    "        d_loss_real = criterion(outputs, real_labels)\n",
    "        real_score = outputs\n",
    "        \n",
    "        # 무작위 텐서로 가짜 이미지 생성\n",
    "        z = torch.randn(BATCH_SIZE, 64).to(DEVICE)\n",
    "        fake_images = G(z)\n",
    "        \n",
    "        # 판별자가 가짜 이미지를 가짜로 인식하는 오차를 계산\n",
    "        outputs = D(fake_images)\n",
    "        d_loss_fake = criterion(outputs, fake_labels)\n",
    "        fake_score = outputs\n",
    "        \n",
    "        # 진짜와 가짜 이미지를 갖고 낸 오차를 더해서 판별자의 오차 계산\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "        # 역전파 알고리즘으로 판별자 모델의 학습을 진행\n",
    "        d_optimizer.zero_grad()\n",
    "        g_optimizer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        # 생성자가 판별자를 속였는지에 대한 오차를 계산\n",
    "        fake_images = G(z)\n",
    "        outputs = D(fake_images)\n",
    "        g_loss = criterion(outputs, real_labels)\n",
    "        \n",
    "        # 역전파 알고리즘으로 생성자 모델의 학습을 진행\n",
    "        d_optimizer.zero_grad()\n",
    "        g_optimizer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        \n",
    "    # 학습 진행 알아보기\n",
    "    print('Epoch [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}' \n",
    "          .format(epoch, EPOCHS, d_loss.item(), g_loss.item(), \n",
    "                  real_score.mean().item(), fake_score.mean().item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습이 끝난 생성자의 결과물을 한번 확인해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.randn(BATCH_SIZE, 64).to(DEVICE)\n",
    "fake_images = G(z)\n",
    "for i in range(10):\n",
    "    fake_images_img = np.reshape(fake_images.data.cpu().numpy()[i],(28, 28))\n",
    "    plt.imshow(fake_images_img, cmap = 'gray')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
